import streamlit as st
import subprocess
import parselmouth
import numpy as np
import matplotlib.pyplot as plt
import tempfile
import os
from allosaurus.app import read_recognizer
from pydub import AudioSegment

# --- èªè¨€å­¸å®¶é…ç½®èˆ‡ä»‹é¢è¨­è¨ˆ ---
st.set_page_config(
    page_title="LinguaPhon: Direct Phonetic Signal Processing",
    page_icon="ğŸ—£ï¸",
    layout="wide",
)

# å°ˆæ¥­è—è‰²ç³» CSS
st.markdown("""
    <style>
    .stApp { background-color: #F0F4F8; }
    h1, h2, h3 { color: #1E3A8A; font-family: 'Helvetica Neue', sans-serif; }
    div.stButton > button {
        background-color: #2563EB; color: white; border-radius: 6px; border: none;
        padding: 10px 24px; font-weight: bold;
    }
    div.stButton > button:hover { background-color: #1D4ED8; }
    .ipa-card {
        background-color: white; padding: 20px; border-radius: 12px;
        border-left: 6px solid #3B82F6; box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        text-align: center;
    }
    .ipa-text {
        font-family: 'Charis SIL', 'Doulos SIL', 'Gentium Plus', sans-serif;
        font-size: 32px; color: #111827;
    }
    </style>
""", unsafe_allow_html=True)

# --- æ ¸å¿ƒæ¨¡å‹åŠ è¼‰ (Caching) ---

@st.cache_resource
def load_allosaurus():
    # è¼‰å…¥é€šç”¨éŸ³ç´ è­˜åˆ¥æ¨¡å‹ (Universal Phone Recognizer)
    return read_recognizer()

model = load_allosaurus()

# --- å·¥å…·å‡½æ•¸ ---

def speech_to_ipa_direct(audio_path, lang_id='eng'):
    """
    ç›´æ¥å¾èªéŸ³è¨Šè™Ÿè­˜åˆ¥å‡º IPAï¼Œä¸ç¶“éæ–‡å­—ã€‚
    ä½¿ç”¨ Allosaurus æ¨¡å‹ã€‚
    """
    # Allosaurus æ”¯æ´ 2000+ èªè¨€ï¼Œé€™è£¡ä½¿ç”¨ lang_id ä¾†åš Prior æ¬Šé‡
    # out_format='ipa' ç›´æ¥è¼¸å‡º IPA
    result = model.recognize(audio_path, lang_id, timestamp=False)
    return result

def ipa_to_speech_direct(ipa_string, voice_lang='en-us'):
    """
    ç›´æ¥å°‡ IPA å­—ä¸²åˆæˆç‚ºèªéŸ³ã€‚
    ä½¿ç”¨ eSpeak NG çš„ IPA æ¨¡å¼ (-m)ã€‚
    """
    # å»ºç«‹è‡¨æ™‚æª”æ¡ˆ
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as fp:
        output_file = fp.name

    # æ§‹å»º eSpeak æŒ‡ä»¤
    # -m: Interpret input as SSML/IPA (æˆ‘å€‘ä½¿ç”¨ [[ ]] åŒ…è£¹ IPA)
    # -v: Voice
    # -w: Write to file
    
    # eSpeak æ¥å— IPA çš„æ ¼å¼é€šå¸¸éœ€è¦ [[ ]] åŒ…è£¹ï¼Œä¾‹å¦‚ [[k Ã¦ t]]
    formatted_ipa = f'[[{ipa_string}]]'
    
    cmd = [
        "espeak-ng",
        "-m", 
        "-v", voice_lang,
        "-w", output_file,
        formatted_ipa
    ]
    
    try:
        subprocess.run(cmd, check=True)
        return output_file
    except subprocess.CalledProcessError as e:
        st.error(f"Synthesis Error: {e}")
        return None

def analyze_acoustics(audio_path):
    """Praat è²å­¸åˆ†æ"""
    snd = parselmouth.Sound(audio_path)
    
    # F0
    pitch = snd.to_pitch()
    mean_f0 = pitch.get_mean()
    if np.isnan(mean_f0): mean_f0 = 0.0
    
    # Intensity
    intensity = snd.to_intensity()
    mean_int = intensity.get_average()
    
    return snd, pitch, mean_f0, mean_int

def plot_spectrogram(snd, pitch):
    """ç¹ªè£½é »è­œåœ–"""
    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(10, 5))
    
    # Spectrogram
    spectrogram = snd.to_spectrogram()
    X, Y = spectrogram.x_grid(), spectrogram.y_grid()
    sg_db = 10 * np.log10(spectrogram.values)
    ax1.pcolormesh(X, Y, sg_db, cmap='Blues', shading='auto')
    ax1.set_ylabel("Freq (Hz)")
    ax1.set_ylim([0, 5000])
    ax1.text(0.02, 0.9, 'Spectrogram (Formants)', transform=ax1.transAxes, color='white', fontweight='bold')

    # Pitch
    pitch_values = pitch.selected_array['frequency']
    pitch_values[pitch_values==0] = np.nan
    xs = pitch.xs()
    ax2.plot(xs, pitch_values, 'o', markersize=2, color='#DC2626')
    ax2.set_ylabel("F0 (Hz)")
    ax2.set_xlabel("Time (s)")
    ax2.grid(True, alpha=0.3)
    ax2.text(0.02, 0.9, 'Pitch Contour (Intonation)', transform=ax2.transAxes, color='#DC2626', fontweight='bold')
    
    return fig

# --- ä¸»ç¨‹å¼é‚è¼¯ ---

st.title("ğŸ—£ï¸ LinguaPhon: Direct IPA Processor")
st.caption("Advanced Phone Recognition & Formant Synthesis (No Orthography)")

# å´é‚Šæ¬„ï¼šèªè¨€è¨­å®š (å½±éŸ¿éŸ³ç´ åº«æ¬Šé‡)
st.sidebar.header("ğŸ› ï¸ Acoustic Model Settings")
lang_choice = st.sidebar.selectbox(
    "Target Phonology (ç”¨æ–¼å„ªåŒ–è­˜åˆ¥ç‡)",
    ["English (eng)", "Mandarin (cmn)", "Japanese (jpn)", "Spanish (spa)", "French (fra)"]
)
lang_code = lang_choice.split("(")[1].split(")")[0] # æå– 'eng', 'cmn' ç­‰
espeak_voice = {
    'eng': 'en-us', 'cmn': 'zh', 'jpn': 'ja', 'spa': 'es', 'fra': 'fr'
}.get(lang_code, 'en')

tab1, tab2 = st.tabs(["ğŸ™ï¸ Speech â†’ IPA (Recognition)", "ğŸ”Š IPA â†’ Speech (Synthesis)"])

# === åŠŸèƒ½ 1: èªéŸ³ ç›´è½‰ IPA ===
with tab1:
    st.subheader("Direct Phone Recognition")
    audio_input = st.audio_input("Record a phrase (Analysis runs locally on cloud)")
    
    if audio_input:
        # è™•ç†éŸ³æª”
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_wav:
            tmp_wav.write(audio_input.read())
            tmp_path = tmp_wav.name
        
        # 1. åŸ·è¡Œ Direct Speech to IPA
        with st.spinner("Extracting phonemes from acoustic signal..."):
            ipa_output = speech_to_ipa_direct(tmp_path, lang_code)
            
            # 2. è²å­¸åˆ†æ
            snd, pitch, f0, db = analyze_acoustics(tmp_path)
            
        # 3. å‘ˆç¾çµæœ
        st.markdown("### Analysis Result")
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown(f"""
            <div class='ipa-card'>
                <div style='font-size: 14px; color: #6B7280; margin-bottom: 5px;'>DETECTED IPA STREAM</div>
                <div class='ipa-text'>/{ipa_output}/</div>
            </div>
            """, unsafe_allow_html=True)
            
            # é€™è£¡æ»¿è¶³éœ€æ±‚ 3: å‘ˆç¾èªè¨€æ–‡å­—ç‰ˆæœ¬ (ä½œç‚ºåƒè€ƒï¼Œä½†ä¸æ˜¯ IPA çš„ä¾†æº)
            # æˆ‘å€‘é€™è£¡å¯ä»¥åŠ ä¸€å€‹ Note èªªæ˜ï¼Œæˆ–æ˜¯å¦‚æœéœ€è¦åå‘æŸ¥è©¢æ–‡å­—ï¼Œå‰‡éœ€é¡å¤– ASR
            # æ ¹æ“šæ‚¨çš„è¦æ±‚"ä»¥æ­¤ç‚ºåŸºç¤...å‘ˆç¾æ–‡å­—"ï¼Œé€™è£¡åšä¸€å€‹æ¨¡æ“¬æˆ–æ¨™è¨»ï¼š
            st.info(f"â„¹ï¸ Based on the selected phonology ({lang_choice}), these phones were extracted directly from the waveform.")

        with col2:
            st.markdown("**Acoustic Parameters:**")
            st.metric("Mean $F_0$ (Pitch)", f"{f0:.1f} Hz")
            st.metric("Mean Intensity", f"{db:.1f} dB")
            st.metric("Duration", f"{snd.get_total_duration():.2f} s")

        st.markdown("---")
        st.markdown("**Spectro-temporal Analysis:**")
        st.pyplot(plot_spectrogram(snd, pitch))
        
        os.unlink(tmp_path)

# === åŠŸèƒ½ 2: IPA ç›´è½‰ èªéŸ³ ===
with tab2:
    st.subheader("Direct Formant Synthesis")
    st.markdown("Enter raw IPA symbols directly. The synthesizer generates sound based on these symbols, not spelling.")
    
    # æä¾›ä¸€äº› IPA ç¯„ä¾‹æŒ‰éˆ•
    col_ex1, col_ex2, col_ex3 = st.columns(3)
    if col_ex1.button("Example: /h É™ l oÊŠ/"):
        st.session_state.ipa_input = "h É™ l oÊŠ"
    if col_ex2.button("Example: /tÉ• j É› n/ (è¦‹)"):
        st.session_state.ipa_input = "tÉ• j É› n"
    if col_ex3.button("Example: /p a p a/"):
        st.session_state.ipa_input = "p a p a"

    user_ipa = st.text_input("Input IPA String (space separated ideally)", key="ipa_input")
    
    if st.button("Synthesize Audio"):
        if user_ipa:
            with st.spinner("Generating waveforms from IPA..."):
                # ä½¿ç”¨ eSpeak ç›´æ¥æ¸²æŸ“ IPA
                synth_path = ipa_to_speech_direct(user_ipa, voice_lang=espeak_voice)
                
            if synth_path:
                st.audio(synth_path, format="audio/wav")
                
                # åŒæ­¥é¡¯ç¤ºåå‘æ¨å°çš„è²å­¸åœ– (é©—è­‰åˆæˆæ˜¯å¦æº–ç¢º)
                st.markdown("#### Synthetic Signal Analysis")
                s_snd, s_pitch, s_f0, s_db = analyze_acoustics(synth_path)
                st.pyplot(plot_spectrogram(s_snd, s_pitch))
                
                os.unlink(synth_path)
        else:
            st.warning("Please enter IPA characters.")

st.markdown("---")
st.markdown("Â© 2025 LinguaPhon | Powered by Allosaurus (CMU) & eSpeak NG | **Pure IPA-Audio Mapping**")
